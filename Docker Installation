	
/var is a standard subdirectory of the root directory in Linux and other Unix-like operating systems that contains files to which the system writes data during the course of its operation.

Among the various subdirectories within /var are /var/cache (contains cached data from application programs), /var/games (contains variable data relating to games in /usr), /var/lib (contains dynamic data libraries and files), /var/lock (contains lock files created by programs to indicate that they are using a particular file or device), /var/log (contains log files), /var/run (contains PIDs and other system information that is valid until the system is booted again) and /var/spool (contains mail, news and printer queues).

sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    software-properties-common
    
    
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo apt-key fingerprint 0EBFCD88


sudo add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"
   
sudo apt-get install docker-ce

Try to access folder of windows from guest OS
What is deafult gateway:
The "default gateway" is simply the IP of the next hop for traffic that is not explicitly routed anywhere else. This will, almost certainly, be an IP address on an interface of a local router. However, it may not be an address on which you can manage the router.

If this is for a "home-type network", the inside IP (your default gateway) and the management address will probably be one and the same, but in a "large/corporate-type network" I wouldn't be so sure.

neststat -rn In computing, netstat (network statistics) is a command-line network utility tool that displays network connections for the Transmission Control Protocol (both incoming and outgoing), routing tables, and a number of network interface (network interface controller or software-defined network interface) and network ...


ps - list processes
-e - show all processes, not just those belonging to the user
-f - show processes in full format (more detailed than default)
command 1 | command 2 - pass output of command 1 as input to command 2
grep find lines containing a pattern
processname - the pattern for grep to search for in the output of ps -ef



How you solved mirror error for alpine : RUN echo " efbj" >> /etc/apk/repository : means alpine some mirror are not supported by apk repo, so we need to externally add mirror

Components of Docker Daemon:

runc :
    create containers
 
containerd :
    executiung container
    push and pull images
Shim :
    stdin and stdout for containers
    update exit status to daemon 
    
 
When you type commands like this into the Docker CLI, the Docker client converts them into the appropriate API payload and POSTs them to the correct API endpoint. The API is implemented in the daemon. It is the same rich, versioned, REST API that has become a hallmark of Docker, and is accepted in the industry as the de facto container API. Once the daemon receives the command to create a new container, it makes a call to containerd.

When you type commands like this into the Docker CLI, the Docker client converts them into the appropriate API payload and POSTs them to the correct API endpoint. The API is implemented in the daemon. It is the same rich, versioned, REST API that has become a hallmark of Docker, and is accepted in the industry as the de facto container API. Once the daemon receives the command to create a new container, it makes a call to containerd.

to perform maintenance and upgrades on the Docker daemon without impacting running containers!

We mentioned earlier that containerd uses runc to create new containers. In fact, it forks a new instance of runc for every container it creates. However, once each container is created, its parent runc process exits. This means we can run hundreds of containers without having to run hundreds of runc instances. Once a container’s parent runc process exits, the associated containerd-shim process becomes the container’s parent. Some of the responsibilities the shim performs as a container’s parent include: Keeping any STDIN and STDOUT streams open so that when the daemon is restarted, the container doesn’t terminate due to pipes being closed etc. Reports the container’s exit status back to the daemon.

some of the major functionality that still exists in the daemon includes; image management, image builds, the REST API, authentication, security, core networking, and orchestration.

some of the major functionality that still exists in the daemon includes; image management, image builds, the REST API, authentication, security, core networking, and orchestration.

If you want to pull images from 3rd party registries (not Docker Hub), you need to prepend the repository name with the DNS name of the registry.

dangling: Accepts true or false, and returns only dangling images (true), or non-dangling images (false). 
before: Requires an image name or ID as argument, and returns all images created before it. 
since: Same as above, but returns images created after the specified image.
label: Filters images based on the presence of a label or label and value. The docker image ls command does not display labels in its output.

By default, Docker will only display 25 lines of results. However, you can use the --limit flag to increase that to a maximum of 100.

The docker history command shows the build history of an image and is not a strict list of layers in the image. For example, some Dockerfile instructions used to build an image do not result in layers being created. These include; “ENV”, “EXPOSE”, “CMD”, and “ENTRYPOINT”. Instead of these creating new layers, they add metadata to the image.

Docker employs a storage driver (snapshotter in newer versions) that is responsible for stacking layers and presenting them as a single unified filesystem. Examples of storage drivers on Linux include AUFS, overlay2, devicemapper, btrfs and zfs.
 

Multiple images can, and do, share layers. This leads to efficiencies in space and performance.

Pulling images by Digest/hash:

So far, we’ve shown you how to pull images by tag, and this is by far the most common way. But it has a problem — tags are mutable! This means it’s possible to accidentally tag an image with the wrong tag. Sometimes it’s even possible to tag an image with the same tag as an existing, but different, image. This can cause problems!

At the time of writing, there is no native Docker command that will retrieve the digest of an image from a remote registry such as Docker Hub. This means the only way to determine the digest of an image is to pull it by tag and then make a note of its digest. This will no doubt change in the future.

The layers are where the data lives (files etc.). Each one is fully independent, and has no concept of being part of a collective image.

when you push an image layer to Docker Hub, Docker Hub will attempt to verify that the image arrived without being tampered with en-route. To do this, it runs a hash against the layer and checks to see if it matches the hash that was sent. Because the layer was compressed (changed) the hash verification will fail.

To get around this, each layer also gets something called a distribution hash. This is a hash of the compressed version of the layer. When a layer is pushed and pulled from the registry, its distribution hash is included, and this is what is used to verify that the layer arrived without being tampered with.

Multi-architecture images


when new platforms and architectures, such as Windows, ARM, and s390x were added. All of a sudden we have to think about whether the image we’re pulling is built for the architecture we’re running on. This breaks the smooth experience.

Docker (image and registry specs) now supports multi-architecture images. This means a single image (repository:tag) can have an image for Linux on x64, Linux on PowerPC, Windows x64, ARM etc. Let me be clear, we’re talking about a single image tag supporting multiple platforms and architectures.

To make this happen, the Registry API supports two important constructs: 
manifest lists (new) 
manifests

When you pull an image, your Docker client makes the relevant calls to the Docker Registry API running on Docker Hub. If a manifest list exists for the image, it will be parsed to see if an entry exists for Linux on ARM. If an ARM entry exists, the manifest for that image is retrieved and parsed for the crypto ID’s of the layers that make up the image. Each layer is then pulled from Docker Hub’s blob store.

Creating images that run on multiple architectures requires additional effort from the image publisher. Also, some software is not cross-platform. With this in mind, manifest lists are optional — if one doesn’t exist for an image, the Registry will return the normal manifest.

However, if an image layer is shared by more than one image, that layer will not be deleted until all images that reference it have been deleted.

At a high level, we can say that hypervisors perform hardware virtualization — they carve up physical hardware resources into virtual versions. On the other hand, containers perform OS virtualization — they carve up OS resources into virtual versions.

The only thing that has an impact on container start time is the time it takes to start the application it’s running.

//Run this command on Linux systems not using Systemd
$ service docker status
docker start/running, process 29393

//Run this command on Linux systems that are using Systemd
$ systemctl is-active docker
active

When we hit Return, the Docker client made the appropriate API calls to the Docker daemon. The Docker daemon accepted the command and searched the Docker host’s local cache to see if it already had a copy of the requested image. In the example cited, it didn’t, so it went to Docker Hub to see if it could find it there. It could, so it pulled it locally and stored it in its local cache.

Try executing some basic commands inside of the container. You might notice that some commands do not work. This is because the images we used, like almost all container images, are highly optimized for containers.

When we started the Ubuntu container in the previous section, we told it to run the Bash shell (/bin/bash). This makes the Bash shell the one and only process running inside of the container.

This means that if you type exit, to exit the Bash shell, the container will also exit (terminate). The reason for this is that a container cannot exist without a running process — killing the Bash shell kills the container’s only process, resulting in the container also being killed. This is also true of Windows containers — killing the main process in the container will also kill the container.

Press Ctrl-PQ to exit the container without terminating it.

It is possible to delete a running container with a single command by passing the -f flag to docker container rm.

And even then, if you’re storing container data in a volume, that data’s going to persist even after the container has gone.

In our previous example the container was running the /bin/bash app. When you kill a running container with docker container rm <container> -f, the container will be killed without warning. The procedure is quite violent — a bit like sneaking up behind the container and shooting it in the back of the head. You’re literally giving the container, and the app it’s running, no chance to straighten its affairs before being killed. However, the docker container stop command is far more polite (like pointing a gun to the containers head and saying “you’ve got 10 seconds to say any final words”). It gives the process inside of the container a heads-up that it’s about to be stopped, giving it a chance to get things in order before the end comes. Once the docker stop command returns, you can then delete the container with docker container rm. The magic behind the scenes here can be explained with Linux/POSIX signals. docker container stop sends a SIGTERM signal to the PID 1 process inside of the container. As we just said, this gives the process a chance to clean things up and gracefully shut itself down. If it doesn’t exit within 10 seconds, it will receive a SIGKILL. This is effectively the bullet to the head. But hey, it got 10 seconds to sort itself out first! docker container rm <container> -f doesn’t bother asking nicely with a SIGTERM, it goes straight to the SIGKILL. Like we said a second ago, this is like creeping up from behind and smashing it over the head. I’m not a violent person by the way!

It’s often a good idea to run containers with a restart policy. It’s a form of self-healing that enables Docker to automatically restart them after certain events or failures have occurred.

writing, the following restart policies exist: 
always 
unless-stopped 
on-failed

always :
Typing exit from the shell will kill the container’s PID 1 process and therefore kill the container. However, Docker will automatically restart it because it was started with the --restart always policy. If you issue a docker container ls command, you will see that the container’s uptime will be less than the time since it was created.

unless -stopped:
The main difference between the always and unless-stopped policies is that containers with the --restart unless-stopped policy will not be restarted when the daemon restarts if they were in the Stopped (Exited) state. That might be a confusing sentence, so let’s walk through an example.

on-failed:
The on-failure policy will restart a container if it exits with a non-zero exit code. It will also restart containers when the Docker daemon restarts, even containers that were in the stopped state.

We know docker container run starts a new container. But this time we give it the -d flag instead of -it. -d stands for daemon mode, and tells the container to run in the background. After that, we name the container and then give it -p 80:8080. The -p flag maps ports on the Docker host to ports inside the container. This time we’re mapping port 80 on the Docker host to port 8080 inside the container.

The directory containing the application is referred to as the build context. It’s a common practice to keep your Dockerfile in the root directory of the build context. It’s also important that Dockerfile starts with a capital “D” and is all one word. “dockerfile” and “Docker file” are not valid.

All Dockerfiles start with the FROM instruction. This will be the base layer of the image, and the rest of the app will be added on top as additional layers.

Next, the Dockerfile creates a LABEL that specifies “nigelpoulton@hotmail.com” as the maintainer of the image. Labels are simple key-value pairs and are an excellent way of adding custom metadata to an image. It’s considered a best practice to list a maintainer of an image so that other potential users have a point of contact when working with it.

Next, the Dockerfile creates a LABEL that specifies “nigelpoulton@hotmail.com” as the maintainer of the image. Labels are simple key-value pairs and are an excellent way of adding custom metadata to an image. It’s considered a best practice to list a maintainer of an image so that other potential users have a point of contact when working with it.

The COPY . /src instruction copies in the app files from the build context. It copies these files into the image as a new layer

Next, the Dockerfile uses the WORKDIR instruction to set the working directory for the rest of the instructions in the file. This directory is relative to the image, and the info is added as metadata to the image config and not as a new layer.

Then the RUN npm install instruction uses npm to install application dependencies listed in the package.json file in the build context. It runs within the context of the WORKDIR set in the previous instruction, and installs the dependencies as a new layer in the image.

The application exposes a web service on TCP port 8080, so the Dockerfile documents this with the EXPOSE 8080 instruction. This is added as image metadata and not an image layer.

You can use the docker image inspect web:latest command to verify the configuration of the image. It will list all of the settings that were configured from the Dockerfile.

In order to push an image to Docker Hub, you need to login with your Docker ID. You also need tag the image appropriately.

Before you can push an image, you need to tag it in a special way. This is because Docker needs all of the following information when pushing an image:
Registry 
Repository 
Tag

Docker is opinionated, so you don’t need to specify values for Registry and Tag. If you don’t specify values, Docker will assume Registry=docker.io and Tag=latest. However, Docker does not have a default value for the Repository value, it gets this from the “REPOSITORY” value of the image it is pushing.

The previous docker image ls output shows our image with web as the repository name. This means a docker image push will try and push the image to docker.io/web:latest. However, I don’t have access to the web repository, all of my images have to sit within the nigelpoulton second-level namespace. This means we need to re-tag the image to include my Docker ID.

The format of the command is docker image tag <current-tag> <new-tag> and it adds an additional tag, it does not overwrite the original.

docker container run -d --name c1 \
  -p 80:8080 \
  web:latest

Comment lines in a Dockerfile start with the # character. All non-comment lines are Instructions. Instructions take the format INSTRUCTION argument. Instruction names are not case sensitive, but it is normal practice to write them in UPPERCASE. This makes reading the Dockerfile easier.

Examples of instructions that create new layers are FROM, RUN, and COPY. Examples of instructions that create metadata include EXPOSE, WORKDIR, ENV, and ENTRYPOINT. The basic premise is this - if an instruction is adding content such as files and programs to the image, it will create a new layer. If it is adding instructions on how to build the image and run the application, it will create metadata. You can view the instructions that were used to build the image with the docker image history command.

First. Each line corresponds to an instruction in the Dockerfile (starting from the bottom and working up). The CREATED BY column even lists the exact Dockerfile instruction that was executed.

Second. Only 4 of the lines displayed in the output create new layers (the ones with non-zero values in the SIZE column). These correspond to the FROM, RUN, and COPY instructions in the Dockerfile. Although the other instructions might look like they create layers, they actually create metadata instead of layers. The reason that the docker image history output makes it looks like all instructions create layers is an artefact of the way Docker builds and image layering used to work.

Use the docker image inspect command to confirm that only 4 layers were created.

It is considered a good practice to use images from official repositories with the FROM instruction. This is because they tend to follow best practices and be relatively free from known vulnerabilities. It is also a good idea to start from (FROM) small images as this reduces potential vulnerabilities.

You can view the output of the docker image build command to see the general process for building an image. As the following snippet shows, the basic process is: spin up a temporary container > run the Dockerfile instruction inside of that container > save the results as a new image layer > remove the temporary container.

Big means slow. Big means hard to work with. And big means a more potential vulnerabilities and possibly a bigger attack surface! For these reasons, Docker images should be small. The aim of the game is to only ship production images containing the stuff needed to run your app in production.

For example, the way you write your Dockerfiles has a huge impact on the size of your images. A common example is that every RUN instruction adds a new layer. As a result, it’s usually considered a best practice to include multiple commands as part of a single RUN instruction - all glued together with double-ampersands (&&) and backslash (\) line-breaks. While this isn’t rocket science, it requires time and discipline.

Another issue is that we don’t clean up after ourselves. We’ll RUN a command against an image that pulls some build-time tools, and we’ll leave all those tools in the image when we ship it to production. Not ideal! 

There were ways around this - most notably the builder pattern. But most of these required discipline and added complexity. 

The builder pattern required you to have at least two Dockerfiles - one for development and one for production. You’d write your Dockerfile.dev to start from a large base image, pull in any additional build tools required, and build your app. You’d then build an image from the Dockerfile.dev and create a container from it. You’d then use your Dockerfile.prod to build a new image from a smaller base image, and copy over just the application stuff from the container you just created from the build image. And everything needed to be glued together with a script.

This approach was doable, but at the expense of complexity. Multi-stage builds to the rescue!

With multi-stage builds, we have a single Dockerfile containing multiple FROM instructions. Each FROM instruction is a new build stage that can easily COPY artefacts from previous stages.

USe cases for multistage builds?

An important thing to note, is that COPY --from instructions are used to only copy production-related application code from the images built by the previous stages. They do not copy across build artefacts that are not needed for production. It’s also important to note that we only need a single Dockerfile, and no extra arguments are needed for the docker image build command!

Leverage the build cache

As we know, the docker image build process iterates through a Dockerfile one-line-at-a-time starting from the top. For each instruction, Docker looks to see if it already has an image layer for that instruction in its cache. If it does, this is a cache hit and it uses that layer. If it doesn’t, this is a cache miss and it builds a new layer from the instruction. Getting cache hits can hugely speed up the build process.

If it finds a layer, it skips the instruction, links to that existing layer, and continues the build with the cache in tact. If it does not find a layer, it invalidates the cache and builds the layer. This operation of invalidating the cache invalidates it for the remainder of the build. This means all subsequent Dockerfile instructions are completed in full without attempting to reference the build cache.

Firstly, as soon as any instruction results in a cache-miss (no layer was found for that instruction), the cache is no longer used for the rest of the entire build. This has an important impact on how you write your Dockerfiles. Try and build them in a way that places any instructions that are likely to change towards the end of the file. This means that a cache-miss will not occur until later stages of the build - allowing the build to benefit as much as possible from the cache.

You can force the build process to ignore the entire cache by passing the --no-cache=true flag to the docker image build command.

It is also important to understand that the COPY and ADD instructions include steps to ensure that the content being copied into the image has not changed since the last build. For example, it’s possible that the COPY . /src instruction in the Dockerfile has not changed since the previous, but… the contents of the directory being copied into the image have changed!

To protect against this, Docker performs a checksum against each file being copied, and compares that to a checksum of the same file in the cached layer. If the checksums do not match, the cache is invalidated and a new layer is built.

Squash the image

At a high level, Docker follows the normal process to build an image, but then adds an additional step that squashes everything into a single layer.

Squashing can be good in situations where images are starting to have a lot of layers and this isn’t ideal. And example might be when creating a new base image that you want to build other images from in the future - this is much better as a single-layer image.

On the negative side, squashed images do not share image layers. This can result in storage inefficiencies and larger push and pull operations.

Add the --squash flag to the docker image build command if you want to create a squashed image.

Figure 8.8 shows some of the inefficiencies that come with squashed images. Both images are exactly the same except for the fact that one is squashed and the other is not. The squashed image shares layers with other images on the host (saving disk space) but the squashed image does not. The squashed image will also need to send every byte to Docker Hub on a docker image push command, whereas the non-squashed image only needs to send unique layers.

Use no-install-recommends

If you are building Linux images, and using the apt package manager, you should use the no-install-recommends flag with the apt-get install command. This makes sure that apt only installs main dependencies (packages in the Depends field) and not recommended or suggested packages. This can greatly reduce the number of unwanted packages that are downloaded into your images.

The -t flag tags the image, and the -f flag lets you specify the name and location of the Dockerfile. With the -f flag, it is possible to use a Dockerfile with an arbitrary name and in an arbitrary location. The build context is where your application files exist, and this can be a directory on your local Docker host or a remote Git repo.

The FROM instruction in a Dockerfile specifies the base image for the new image you will build. It is usually the first instruction in a Dockerfile.

The RUN instruction in a Dockerfile allows you to run commands inside the image which create new layers. Each RUN instruction creates a single new layer.

The COPY instruction in a Dockerfile adds files into the image as a new layer. It is common to use the COPY instruction to copy your application code into an image.

The EXPOSE instruction in a Dockerfile documents the network port that the application uses.

The ENTRYPOINT instruction in a Dockerfile sets the default application to run when the image is started as a container.

Other Dockerfile instructions include LABEL, ENV, ONBUILD, HEALTHCHECK, CMD and more…


















